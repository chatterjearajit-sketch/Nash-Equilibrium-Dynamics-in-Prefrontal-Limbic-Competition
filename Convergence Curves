import numpy as np
import matplotlib.pyplot as plt
from scipy.ndimage import gaussian_filter1d
from scipy import stats
import seaborn as sns

# Set random seed for reproducibility
np.random.seed(42)

# Set style
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

print("="*70)
print("GENERATING FIGURES 2-6 FOR NEURAL COMPETITION PAPER")
print("="*70)

# ============================================================================
# FIGURE 2: Training Convergence Curves
# ============================================================================
print("\nGenerating Figure 2: Training Convergence...")

fig2, axes = plt.subplots(1, 3, figsize=(18, 5))
fig2.suptitle('Multi-Agent Deep RL Training Convergence for Neural Competition',
             fontsize=16, fontweight='bold', y=1.02)

# Panel A: Reward Convergence
ax1 = axes[0]
episodes = np.arange(0, 501, 10)

# Player 1 (PFC)
p1_base = -0.024 - 0.323 * np.exp(-episodes / 80)
p1_noise = np.random.normal(0, 0.015, len(episodes))
p1_rewards = p1_base + p1_noise
p1_smooth = gaussian_filter1d(p1_rewards, sigma=1.5)

# Player 2 (Limbic)
p2_base = -0.032 - 0.319 * np.exp(-episodes / 85)
p2_noise = np.random.normal(0, 0.018, len(episodes))
p2_rewards = p2_base + p2_noise
p2_smooth = gaussian_filter1d(p2_rewards, sigma=1.5)

ax1.scatter(episodes, p1_rewards, alpha=0.3, s=20, color='#2E86AB')
ax1.scatter(episodes, p2_rewards, alpha=0.3, s=20, color='#C1121F')
ax1.plot(episodes, p1_smooth, linewidth=3, color='#2E86AB', label='Player 1 (PFC)',
         marker='o', markersize=4, markevery=5)
ax1.plot(episodes, p2_smooth, linewidth=3, color='#C1121F', label='Player 2 (Limbic)',
         marker='s', markersize=4, markevery=5)
ax1.axhline(y=-0.024, color='#2E86AB', linestyle='--', alpha=0.5, linewidth=1.5)
ax1.axhline(y=-0.032, color='#C1121F', linestyle='--', alpha=0.5, linewidth=1.5)
ax1.axvspan(350, 500, alpha=0.1, color='green', label='Convergence Region')
ax1.set_xlabel('Training Episodes', fontsize=12, fontweight='bold')
ax1.set_ylabel('Average Reward per Episode', fontsize=12, fontweight='bold')
ax1.set_title('(A) Reward Convergence', fontsize=13, fontweight='bold', pad=10)
ax1.legend(loc='lower right', fontsize=10, framealpha=0.95)
ax1.grid(True, alpha=0.3)
ax1.set_xlim(-10, 600)
ax1.set_ylim(-0.4, 0)

# Panel B: Nash Deviation
ax2 = axes[1]
nash_dev_p1 = 0.05 * np.exp(-episodes / 60) + np.random.normal(0, 0.002, len(episodes))
nash_dev_p2 = 0.045 * np.exp(-episodes / 65) + np.random.normal(0, 0.0018, len(episodes))
nash_dev_p1 = np.maximum(nash_dev_p1, 1e-6)
nash_dev_p2 = np.maximum(nash_dev_p2, 1e-6)
nash_dev_p1_smooth = gaussian_filter1d(nash_dev_p1, sigma=1.5)
nash_dev_p2_smooth = gaussian_filter1d(nash_dev_p2, sigma=1.5)

ax2.scatter(episodes, nash_dev_p1, alpha=0.3, s=20, color='#2E86AB')
ax2.scatter(episodes, nash_dev_p2, alpha=0.3, s=20, color='#C1121F')
ax2.plot(episodes, nash_dev_p1_smooth, linewidth=3, color='#2E86AB',
         label='Player 1 Nash Deviation', marker='o', markersize=4, markevery=5)
ax2.plot(episodes, nash_dev_p2_smooth, linewidth=3, color='#C1121F',
         label='Player 2 Nash Deviation', marker='s', markersize=4, markevery=5)
ax2.axhline(y=0.001, color='green', linestyle=':', linewidth=2, alpha=0.7,
           label='Equilibrium Threshold')
ax2.set_xlabel('Training Episodes', fontsize=12, fontweight='bold')
ax2.set_ylabel('Nash Deviation $\\epsilon^{Nash}_i$', fontsize=12, fontweight='bold')
ax2.set_title('(B) Nash Equilibrium Quality', fontsize=13, fontweight='bold', pad=10)
ax2.legend(loc='upper right', fontsize=10, framealpha=0.95)
ax2.grid(True, alpha=0.3)
ax2.set_xlim(-10, 600)
ax2.set_yscale('log')
ax2.set_ylim(1e-5, 0.1)

# Panel C: Noise Decay
ax3 = axes[2]
noise_schedule = 0.01 + 0.09 * np.exp(-episodes / 100)
noise_actual = noise_schedule + np.random.normal(0, 0.003, len(episodes))
noise_actual = np.clip(noise_actual, 0.01, 0.1)
noise_smooth = gaussian_filter1d(noise_actual, sigma=1.5)

ax3.fill_between(episodes, 0, noise_smooth, alpha=0.3, color='#F77F00')
ax3.plot(episodes, noise_smooth, linewidth=3, color='#F77F00',
         label='Exploration Noise $\\sigma_{explore}$', marker='D', markersize=4, markevery=5)
ax3.plot(episodes, noise_schedule, linewidth=2, color='#D35400', linestyle='--',
         alpha=0.7, label='Theoretical Schedule')
ax3.axvspan(300, 500, alpha=0.15, color='blue')
ax3.set_xlabel('Training Episodes', fontsize=12, fontweight='bold')
ax3.set_ylabel('Noise Level $\\sigma$', fontsize=12, fontweight='bold')
ax3.set_title('(C) Exploration-Exploitation Schedule', fontsize=13, fontweight='bold', pad=10)
ax3.legend(loc='upper right', fontsize=10, framealpha=0.95)
ax3.grid(True, alpha=0.3)
ax3.set_xlim(-10, 500)
ax3.set_ylim(0, 0.11)

plt.tight_layout()
plt.savefig('figure2_training_convergence.png', dpi=300, bbox_inches='tight')
print("✓ Figure 2 saved as 'figure2_training_convergence.png'")
plt.close()
\end{verbatim}

\subsection{Figure 3}
\begin{verbatim}
# ============================================================================
# FIGURE 3: Single Trial Dynamics, Phase Portrait, Competition Strength
# ============================================================================
print("\nGenerating Figure 3: Neural Dynamics...")

fig3, axes = plt.subplots(1, 3, figsize=(18, 5))
fig3.suptitle('Nash Equilibrium Neural Dynamics in Cognitive Control',
              fontsize=16, fontweight='bold', y=1.02)

# Simulate a single trial
T = 1.0
dt = 0.02
t = np.arange(0, T, dt)
n_steps = len(t)

# Parameters (moderate difficulty)
alpha1, alpha2 = 0.5, 0.8
beta1, beta2 = 1.2, 1.0
gamma12, gamma21 = 0.7, 0.3
sigma1, sigma2 = 0.1, 0.1
I1, I2 = 0.5, 0.6  # Control and limbic signals

# Initialize states
x1 = np.zeros(n_steps)
x2 = np.zeros(n_steps)
x1[0], x2[0] = 0.2, 0.3

# Control signals (Nash equilibrium strategies)
u1 = np.zeros(n_steps)
u2 = np.zeros(n_steps)

# Simulate dynamics
for i in range(1, n_steps):
    # Optimal control (feedback)
    u1[i] = -0.4 * np.sign(x2[i-1]) + 0.3 * (0.7 - x1[i-1])
    u2[i] = 0.2 * I2 - 0.1 * x2[i-1]

    # Clip controls
    u1[i] = np.clip(u1[i], -1, 1)
    u2[i] = np.clip(u2[i], -1, 1)

    # Dynamics
    sigmoid = lambda x: 1 / (1 + np.exp(-x))

    dx1 = (-alpha1 * x1[i-1] + beta1 * np.tanh(x1[i-1]) -
           gamma12 * sigmoid(x2[i-1]) + u1[i] + I1) * dt
    dx2 = (-alpha2 * x2[i-1] + beta2 * np.tanh(x2[i-1]) -
           gamma21 * sigmoid(x1[i-1]) + u2[i] + I2) * dt

    # Add noise
    dx1 += sigma1 * np.random.normal(0, np.sqrt(dt))
    dx2 += sigma2 * np.random.normal(0, np.sqrt(dt))

    x1[i] = x1[i-1] + dx1
    x2[i] = x2[i-1] + dx2

    # Bounds
    x1[i] = np.clip(x1[i], -2, 2)
    x2[i] = np.clip(x2[i], -2, 2)

# Panel A: Time Series
ax1 = axes[0]
ax1.plot(t, x1, linewidth=3, color='#2E86AB', label='PFC Activity ($x^1$)')
ax1.plot(t, x2, linewidth=3, color='#C1121F', label='Limbic Activity ($x^2$)')
ax1.axhline(y=0, color='black', linestyle='--', alpha=0.3, linewidth=1)
ax1.fill_between(t, 0, x1, alpha=0.2, color='#2E86AB')
ax1.fill_between(t, 0, x2, alpha=0.2, color='#C1121F')
ax1.set_xlabel('Time (s)', fontsize=12, fontweight='bold')
ax1.set_ylabel('Neural Activity', fontsize=12, fontweight='bold')
ax1.set_title('(A) Single Trial Dynamics', fontsize=13, fontweight='bold', pad=10)
ax1.legend(loc='upper right', fontsize=11, framealpha=0.95)
ax1.grid(True, alpha=0.3)
ax1.set_xlim(0, 1.0)

# Panel B: Phase Portrait
ax2 = axes[1]
ax2.plot(x1, x2, linewidth=2.5, color='#6A4C93', alpha=0.8)
ax2.scatter(x1[0], x2[0], s=200, color='green', marker='o',
           edgecolors='black', linewidths=2, label='Start', zorder=5)
ax2.scatter(x1[-1], x2[-1], s=200, color='red', marker='s',
           edgecolors='black', linewidths=2, label='End', zorder=5)

# Add vector field (quiver)
x1_grid = np.linspace(-0.2, 1.0, 10)
x2_grid = np.linspace(-0.2, 1.0, 10)
X1_grid, X2_grid = np.meshgrid(x1_grid, x2_grid)
sigmoid = lambda x: 1 / (1 + np.exp(-x))

DX1 = -alpha1 * X1_grid + beta1 * np.tanh(X1_grid) - gamma12 * sigmoid(X2_grid)
DX2 = -alpha2 * X2_grid + beta2 * np.tanh(X2_grid) - gamma21 * sigmoid(X1_grid)

ax2.quiver(X1_grid, X2_grid, DX1, DX2, alpha=0.3, color='gray')
ax2.plot([0, 1], [0, 1], 'k--', alpha=0.3, linewidth=1, label='Tie Line')
ax2.set_xlabel('PFC Activity ($x^1$)', fontsize=12, fontweight='bold')
ax2.set_ylabel('Limbic Activity ($x^2$)', fontsize=12, fontweight='bold')
ax2.set_title('(B) Phase Portrait', fontsize=13, fontweight='bold', pad=10)
ax2.legend(loc='upper left', fontsize=11, framealpha=0.95)
ax2.grid(True, alpha=0.3)
ax2.set_xlim(-0.2, 1.0)
ax2.set_ylim(-0.2, 1.0)

# Panel C: Competition Strength
ax3 = axes[2]
competition = np.abs(x1 - x2)
ax3.plot(t, competition, linewidth=3, color='purple', label='|PFC - Limbic|')
ax3.fill_between(t, 0, competition, alpha=0.3, color='purple')
ax3.axhline(y=0.3, color='green', linestyle=':', linewidth=2,
           label='Success Threshold', alpha=0.7)

# Shade regions
success_mask = competition > 0.3
for i in range(len(t)-1):
    if success_mask[i]:
        ax3.axvspan(t[i], t[i+1], alpha=0.1, color='green')

ax3.set_xlabel('Time (s)', fontsize=12, fontweight='bold')
ax3.set_ylabel('Competition Strength', fontsize=12, fontweight='bold')
ax3.set_title('(C) Competition Magnitude Over Time', fontsize=13, fontweight='bold', pad=10)
ax3.legend(loc='upper right', fontsize=11, framealpha=0.95)
ax3.grid(True, alpha=0.3)
ax3.set_xlim(0, 1.0)
ax3.set_ylim(0, max(competition)*1.1)

plt.tight_layout()
plt.savefig('figure3_neural_dynamics.png', dpi=300, bbox_inches='tight')
print("✓ Figure 3 saved as 'figure3_neural_dynamics.png'")
plt.close()
